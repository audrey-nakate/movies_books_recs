{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b606022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from surprise import Dataset, Reader, SVD, BaselineOnly, SVDpp, NMF, SlopeOne, CoClustering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c597e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise.prediction_algorithms import KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore\n",
    "from surprise import accuracy\n",
    "from surprise import dump\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b828718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"D:\\\\Year 3 Semester 2\\\\computerScienceProject\\\\tmdb_5000_movies.csv\")\n",
    "credits_df = pd.read_csv(\"D:\\\\Year 3 Semester 2\\\\computerScienceProject\\\\tmdb_5000_credits.csv\")\n",
    "ratings_df = pd.read_excel(\"D:\\\\Year 3 Semester 2\\\\computerScienceProject\\\\movie_ratings.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb0a5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# book_ratings_df = pd.read_excel(\"D:\\Year 3 Semester 2\\computerScienceProject\\BX-Book-Ratings.xlsx\")\n",
    "# books_df = pd.read_csv(\"D:\\Year 3 Semester 2\\computerScienceProject\\BX-Books.csv\", sep=\";\", error_bad_lines=False, encoding=\"latin-1\")\n",
    "# books_df.columns = [\"ISBN\",\"Title\",\"Author\",\"Year_Of_Publication\",\"Publisher\",\"Image-URL-S\",\"Image-URL-M\",\"Image-URL-L\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c431c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two datasets\n",
    "movies_df = movies_df.merge(credits_df, on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b58530dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.merge(ratings_df, on='movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92ca0765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting relevant columns\n",
    "movies_final = movies_df[[ 'id', 'title', 'genres', 'runtime', 'overview', 'keywords', 'cast', 'crew', 'User_ID', 'RATINGS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7260e985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "title       0\n",
      "genres      0\n",
      "runtime     2\n",
      "overview    3\n",
      "keywords    0\n",
      "cast        0\n",
      "crew        0\n",
      "User_ID     0\n",
      "RATINGS     1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for null values\n",
    "print(movies_final.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5a6233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\326592079.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#drop null values\n",
    "movies_final.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0bfe27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_df = books_df.merge(book_ratings_df, on='ISBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a827361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_final = books_df[['ISBN', 'Title', 'Author', 'Year_Of_Publication', 'Publisher', 'User_ID', 'Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a938e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(books_final.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d0602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\2571114438.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['genres'] = movies_final['genres'].apply(convert)\n"
     ]
    }
   ],
   "source": [
    "#function to extract genre name\n",
    "def convert(obj):\n",
    "    l = []\n",
    "\n",
    "    for i in ast.literal_eval(obj):\n",
    "        l.append(i['name'])\n",
    "    return l\n",
    "\n",
    "movies_final['genres'] = movies_final['genres'].apply(convert)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4157e9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\190040370.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['keywords'] = movies_final['keywords'].apply(convert)\n"
     ]
    }
   ],
   "source": [
    "movies_final['keywords'] = movies_final['keywords'].apply(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d85e8aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\65014636.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['cast'] = movies_final['cast'].apply(convert3)\n"
     ]
    }
   ],
   "source": [
    "#function to extract first three cast names\n",
    "def convert3(obj):\n",
    "    l = []\n",
    "    counter = 0\n",
    "\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if counter != 3:\n",
    "            l.append(i['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return l\n",
    "\n",
    "movies_final['cast'] = movies_final['cast'].apply(convert3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "328cad33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\550475311.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['crew'] = movies_final['crew'].apply(extract_director)\n"
     ]
    }
   ],
   "source": [
    "# to extract director's name\n",
    "def extract_director(obj):\n",
    "    l = []\n",
    "\n",
    "    for i in ast.literal_eval(obj):\n",
    "        if i['job'] == 'Director':\n",
    "            l.append(i['name'])\n",
    "            break\n",
    "    return l\n",
    "\n",
    "movies_final['crew'] = movies_final['crew'].apply(extract_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87f0b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\2814892025.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['overview'] = movies_final['overview'].apply(lambda x: x.split())\n"
     ]
    }
   ],
   "source": [
    "movies_final['overview'] = movies_final['overview'].apply(lambda x: x.split()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b144ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\361890825.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['genres'] = movies_final['genres'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\361890825.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['keywords'] = movies_final['keywords'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\361890825.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['cast'] = movies_final['cast'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\361890825.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['crew'] = movies_final['crew'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n"
     ]
    }
   ],
   "source": [
    "# removing spaces between words\n",
    "movies_final['genres'] = movies_final['genres'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
    "movies_final['keywords'] = movies_final['keywords'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
    "movies_final['cast'] = movies_final['cast'].apply(lambda x : [i.replace(\" \", \"\") for i in x])\n",
    "movies_final['crew'] = movies_final['crew'].apply(lambda x : [i.replace(\" \", \"\") for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33f416c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\451815744.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies_final['tags'] = movies_final['genres'] + movies_final['keywords'] + movies_final['cast'] + movies_final['crew'] + movies_final['overview']\n"
     ]
    }
   ],
   "source": [
    "movies_final['tags'] = movies_final['genres'] + movies_final['keywords'] + movies_final['cast'] + movies_final['crew'] + movies_final['overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd9a5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books_final['tags'] = books_final['Author'] + books_final['Publisher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "284d737d",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies_final[['id', 'title', 'tags', 'User_ID', 'RATINGS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6db2de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books = books_final[['ISBN', 'Title', 'tags', 'User_ID', 'Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d499135a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\3007261697.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies['tags'] = movies['tags'].apply(lambda x : \" \".join(x))\n"
     ]
    }
   ],
   "source": [
    "movies['tags'] = movies['tags'].apply(lambda x : \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11fc6b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\2861373371.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies['tags'] = movies['tags'].apply(lambda x : x.lower())\n"
     ]
    }
   ],
   "source": [
    "movies['tags'] = movies['tags'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c962f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'books' is your DataFrame containing ratings data\n",
    "# # Step 1: Check unique values in the 'Rating' column\n",
    "# print(books['Rating'].unique())\n",
    "\n",
    "# # Step 2: Handle non-numeric values\n",
    "# # For example, if '\"' is a non-numeric value, you can replace it with NaN\n",
    "# books['Rating'] = pd.to_numeric(books['Rating'], errors='coerce')\n",
    "\n",
    "# # Step 3: Convert the 'Rating' column to float\n",
    "# books['Rating'] = books['Rating'].astype(float)\n",
    "\n",
    "# # Now you can load the data into Surprise's Dataset\n",
    "# reader = Reader(rating_scale=(1, 10))\n",
    "# data = Dataset.load_from_df(books[['ISBN', 'User_ID', 'Rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03913e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14844\\1226471429.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movies['RATINGS'] = movies['RATINGS'].replace(0, 1)\n"
     ]
    }
   ],
   "source": [
    "movies['RATINGS'] = movies['RATINGS'].replace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab8b226c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>RATINGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>action adventure fantasy sciencefiction cultur...</td>\n",
       "      <td>227945</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>adventure fantasy action ocean drugabuse exoti...</td>\n",
       "      <td>250634</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>action adventure crime spy basedonnovel secret...</td>\n",
       "      <td>250634</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>action crime drama thriller dccomics crimefigh...</td>\n",
       "      <td>250634</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>action adventure sciencefiction basedonnovel m...</td>\n",
       "      <td>250634</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803</th>\n",
       "      <td>67238</td>\n",
       "      <td>Cavite</td>\n",
       "      <td>foreign thriller neilldelallana adam, a securi...</td>\n",
       "      <td>244349</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4804</th>\n",
       "      <td>9367</td>\n",
       "      <td>El Mariachi</td>\n",
       "      <td>action crime thriller unitedstates–mexicobarri...</td>\n",
       "      <td>244349</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4805</th>\n",
       "      <td>72766</td>\n",
       "      <td>Newlyweds</td>\n",
       "      <td>comedy romance edwardburns kerrybishé marshadi...</td>\n",
       "      <td>244349</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>231617</td>\n",
       "      <td>Signed, Sealed, Delivered</td>\n",
       "      <td>comedy drama romance tvmovie date loveatfirsts...</td>\n",
       "      <td>244341</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4807</th>\n",
       "      <td>126186</td>\n",
       "      <td>Shanghai Calling</td>\n",
       "      <td>danielhenney elizacoupe billpaxton danielhsia ...</td>\n",
       "      <td>244324</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4805 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                     title  \\\n",
       "0      19995                                    Avatar   \n",
       "1        285  Pirates of the Caribbean: At World's End   \n",
       "2     206647                                   Spectre   \n",
       "3      49026                     The Dark Knight Rises   \n",
       "4      49529                               John Carter   \n",
       "...      ...                                       ...   \n",
       "4803   67238                                    Cavite   \n",
       "4804    9367                               El Mariachi   \n",
       "4805   72766                                 Newlyweds   \n",
       "4806  231617                 Signed, Sealed, Delivered   \n",
       "4807  126186                          Shanghai Calling   \n",
       "\n",
       "                                                   tags User_ID  RATINGS  \n",
       "0     action adventure fantasy sciencefiction cultur...  227945     10.0  \n",
       "1     adventure fantasy action ocean drugabuse exoti...  250634     10.0  \n",
       "2     action adventure crime spy basedonnovel secret...  250634     10.0  \n",
       "3     action crime drama thriller dccomics crimefigh...  250634     10.0  \n",
       "4     action adventure sciencefiction basedonnovel m...  250634     10.0  \n",
       "...                                                 ...     ...      ...  \n",
       "4803  foreign thriller neilldelallana adam, a securi...  244349      1.0  \n",
       "4804  action crime thriller unitedstates–mexicobarri...  244349      1.0  \n",
       "4805  comedy romance edwardburns kerrybishé marshadi...  244349      1.0  \n",
       "4806  comedy drama romance tvmovie date loveatfirsts...  244341      1.0  \n",
       "4807  danielhenney elizacoupe billpaxton danielhsia ...  244324      1.0  \n",
       "\n",
       "[4805 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "496b89fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale = (1, 10))\n",
    "data = Dataset.load_from_df(movies[['id', 'User_ID', 'RATINGS']], reader)\n",
    "traindf = data.build_full_trainset()\n",
    "testdf = traindf.build_anti_testset()\n",
    "# # testdf = filter(lambda x : x[0] == User_ID, testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00ede206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m knnbaseline_model \u001b[38;5;241m=\u001b[39m KNNBaseline(sim_options\u001b[38;5;241m=\u001b[39msim_options)\n\u001b[0;32m      8\u001b[0m knnbaseline_model\u001b[38;5;241m.\u001b[39mfit(traindf)\n\u001b[1;32m----> 9\u001b[0m knnbaseline_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mknnbaseline_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mrmse(knnbaseline_predictions)\n\u001b[0;32m     11\u001b[0m accuracy\u001b[38;5;241m.\u001b[39mmae(knnbaseline_predictions)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:160\u001b[0m, in \u001b[0;36mAlgoBase.test\u001b[1;34m(self, testset, verbose)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(uid, iid, r_ui_trans, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[0;32m    163\u001b[0m ]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:161\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_ui_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[0;32m    163\u001b[0m ]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:102\u001b[0m, in \u001b[0;36mAlgoBase.predict\u001b[1;34m(self, uid, iid, r_ui, clip, verbose)\u001b[0m\n\u001b[0;32m    100\u001b[0m details \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m     est \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miuid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miiid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# If the details dict was also returned\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(est, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\surprise\\prediction_algorithms\\knns.py:321\u001b[0m, in \u001b[0;36mKNNBaseline.estimate\u001b[1;34m(self, u, i)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# just baseline again\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m details \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual_k\u001b[39m\u001b[38;5;124m\"\u001b[39m: actual_k}\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m est, details\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# basic collaborative filtering algorithms\n",
    "sim_options = {'name' : 'cosine',\n",
    "               'user_based' : False  #defining similarity measures\n",
    "              }\n",
    "               \n",
    "knnbaseline_model = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "knnbaseline_model.fit(traindf)\n",
    "knnbaseline_predictions = knnbaseline_model.test(testdf)\n",
    "accuracy.rmse(knnbaseline_predictions)\n",
    "accuracy.mae(knnbaseline_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85ce0e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svd_model = SVD()\n",
    "\n",
    "# svd_model.fit(traindf)\n",
    "# svd_model_predictions = svd_model.test(testdf)\n",
    "\n",
    "# accuracy.rmse(svd_model_predictions)\n",
    "# accuracy.mae(svd_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d98a8f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5509\n",
      "MAE:  0.4447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4447363814175227"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdpp_model = SVDpp()\n",
    "\n",
    "svdpp_model.fit(traindf)\n",
    "svdpp_model_predictions = svdpp_model.test(testdf)\n",
    "\n",
    "accuracy.rmse(svdpp_model_predictions)\n",
    "accuracy.mae(svdpp_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbbef157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  content-based filtering\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "content_matrix = tfidf_vectorizer.fit_transform(movies['tags'])\n",
    "content_similarity = linear_kernel(content_matrix, content_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_content_based_recs(id, top_n):\n",
    "#     index = movies[movies['id'] == id].index[0]\n",
    "#     similarity_scores = content_similarity[index]\n",
    "#     similar_indices = similarity_scores.argsort()[::-1][1:top_n + 1]\n",
    "#     recommendations = movies.loc[similar_indices, 'id']\n",
    "#     return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15111073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #second, collaborative filtering\n",
    "# collab_model = SVD()\n",
    "# trainset = data.build_full_trainset()\n",
    "# collab_model.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a01af72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_collab_recs(User_ID, top_n):\n",
    "#     testset = trainset.build_anti_testset()\n",
    "#     testset = filter(lambda x : x[0] == User_ID, testset)\n",
    "#     predictions = collab_model.test(testset)\n",
    "#     predictions.sort(key=lambda x : x.est, reverse=True)\n",
    "#     recommendations = [predictions.iid for prediction in predictions[:top_n]]\n",
    "#     return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13499ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #now, hybrid filtering\n",
    "# def get_hybrid_recs(id, User_ID, top_n):\n",
    "#     content_based_recs = get_content_based_recs(id, top_n)\n",
    "#     collaborative_recs = get_collab_recs(User_ID, top_n)\n",
    "#     hybrid_recs = list(set(content_based_recs + collaborative_recs))\n",
    "#     return hybrid_recs[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #tryout\n",
    "# User_ID = 2408\n",
    "# id = 285\n",
    "# top_n = 10\n",
    "# recommendations = get_hybrid_recs(id, User_ID, top_n)\n",
    "\n",
    "# print(f\"Hybrid Recommendations for User {User_ID} based on Product {id}:\")\n",
    "# for i, recommendation in enumerate(recommendations):\n",
    "#     print(f\"{i + 1}. Product ID: {recommendation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3828d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = pd.Series(movies.index, index=movies['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed0e1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommender function based on metadata\n",
    "def metadata_recs(movie_input):\n",
    "    index = mapping[movie_input]\n",
    "    \n",
    "    #get similarity with other movies\n",
    "    similarity_score = list(enumerate(content_similarity[index]))\n",
    "    similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the scores of the 15 most similar movies. Ignore the first movie.\n",
    "    similarity_score = similarity_score[1:15]\n",
    "    indices = [i[0] for i in similarity_score]\n",
    "    return (movies['title'].iloc[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4660df56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2315                           Out of Inferno\n",
       "39                               TRON: Legacy\n",
       "3136                        Of Horses and Men\n",
       "1701                                  Aladdin\n",
       "330     The Lord of the Rings: The Two Towers\n",
       "4174                              Man on Wire\n",
       "3998                       The Black Stallion\n",
       "269                 The Princess and the Frog\n",
       "3889                                    Feast\n",
       "950                            The Negotiator\n",
       "1990                The Thief and the Cobbler\n",
       "4665                               Horse Camp\n",
       "403                          Last Action Hero\n",
       "1476                                   Stolen\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_recs = metadata_recs('Tangled')\n",
    "content_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def hybrid(User_ID):\n",
    "#     user_movies = test_data[test_data['User_ID'] == User_ID]\n",
    "#     user_movies['est'] = user_movies['id'].apply(lambda x: 0.6*svdpp_model.predict(User_ID, x).est + 0.4*metadata_recs.predict(User_ID, x).est)    \n",
    "#     user_movies = user_movies.sort_values(by ='est', ascending=False).head(4)\n",
    "#     user_movies['Model'] = 'svdpp + cb'\n",
    "# #     user_movies = user_movies['movieId'].values.tolist()\n",
    "# #     print(\"User liked movies list: \", user_movies)\n",
    "    \n",
    "#     recommend_list = user_movies[['id', 'est', 'Model']]\n",
    "#     print(recommend_list.head())\n",
    "#     return recommend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5042d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# class HybridRecommendationSystem:\n",
    "#     def __init__(self, user_item_matrix, item_features):\n",
    "#         self.user_item_matrix = user_item_matrix\n",
    "#         self.item_features = item_features\n",
    "\n",
    "#     def collaborative_filtering(self, user_id, top_n):\n",
    "#         # Compute similarity between users using cosine similarity\n",
    "#         user_similarity = cosine_similarity(self.user_item_matrix)\n",
    "        \n",
    "#         # Get top N similar users\n",
    "#         similar_users = user_similarity[user_id].argsort()[::-1][:top_n]\n",
    "\n",
    "#         # Aggregate recommendations from similar users\n",
    "#         recommendations = []\n",
    "#         for user in similar_users:\n",
    "#             user_ratings = self.user_item_matrix[user]\n",
    "#             for item, rating in enumerate(user_ratings):\n",
    "#                 if rating > 0 and self.user_item_matrix[user_id][item] == 0:\n",
    "#                     recommendations.append(item)\n",
    "#                     if len(recommendations) >= top_n:\n",
    "#                         return recommendations\n",
    "        \n",
    "#         return recommendations\n",
    "\n",
    "#     def content_based_filtering(self, user_id, top_n):\n",
    "#         # Convert item features into TF-IDF vectors\n",
    "#         tfidf_vectorizer = TfidfVectorizer()\n",
    "#         tfidf_matrix = tfidf_vectorizer.fit_transform(self.item_features)\n",
    "\n",
    "#         # Compute similarity between items based on their features\n",
    "#         item_similarity = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "#         # Get top N similar items\n",
    "#         similar_items = item_similarity.argsort()[::-1][user_id][:top_n]\n",
    "\n",
    "#         return similar_items\n",
    "\n",
    "#     def hybrid_recommendation(self, user_id, top_n):\n",
    "#         collaborative_rec = self.collaborative_filtering(user_id, top_n)\n",
    "#         content_based_rec = self.content_based_filtering(user_id, top_n)\n",
    "\n",
    "#         # Combine recommendations, for example, by merging the lists and removing duplicates\n",
    "#         hybrid_rec = collaborative_rec + content_based_rec\n",
    "#         hybrid_rec = list(set(hybrid_rec))  # Remove duplicates\n",
    "        \n",
    "#         return hybrid_rec[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7535bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def combine_recommendations(svdpp_model_predictions, content_recs, weight_collab=0.5):\n",
    "#     # Here you can implement a strategy to combine the recommendations\n",
    "#     # For example, weighted average:\n",
    "#     hybrid_scores = weight_collab * svdpp_model_predictions + (1 - weight_collab) * content_recs\n",
    "def combine_recommendations(svdpp_model_predictions, content_recs, weight_collab=0.5):\n",
    "    # Convert svdpp_model_predictions to a list of recommended items\n",
    "    svdpp_items = [prediction.iid for prediction in svdpp_model_predictions]\n",
    "    \n",
    "    # Combine recommendations using the specified weight\n",
    "    hybrid_scores = []\n",
    "    for prediction in svdpp_model_predictions:\n",
    "        for content_score in content_recs:\n",
    "           hybrid_scores.append((weight_collab * prediction.est) + ((1 - weight_collab) * content_score))\n",
    "    \n",
    "    # Combine the recommended items from collaborative and content-based filtering\n",
    "    hybrid_items = svdpp_items * len(content_recs)\n",
    "    \n",
    "    # Combine the scores and items into tuples\n",
    "    hybrid = list(zip(hybrid_items, hybrid_scores))\n",
    "    \n",
    "    # Sort the hybrid recommendations by score in descending order\n",
    "    hybrid.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Extract only the recommended items from the sorted hybrid list\n",
    "    hybrid = [item for item, _ in hybrid]\n",
    "    \n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44a51a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recs(movie_input):\n",
    "#     collab = svdpp_model\n",
    "#     content = metadata_recs(movie_input)\n",
    "    \n",
    "#     hybrid = collab + content\n",
    "#     hybrid = list(set(hybrid))\n",
    "      hybrid = combine_recommendations(svdpp_model_predictions, content_recs)\n",
    "    \n",
    "      return hybrid[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33fed2e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcombine_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvdpp_model_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_recs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 13\u001b[0m, in \u001b[0;36mcombine_recommendations\u001b[1;34m(svdpp_model_predictions, content_recs, weight_collab)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m svdpp_model_predictions:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m content_score \u001b[38;5;129;01min\u001b[39;00m content_recs:\n\u001b[1;32m---> 13\u001b[0m        hybrid_scores\u001b[38;5;241m.\u001b[39mappend[(weight_collab \u001b[38;5;241m*\u001b[39m prediction\u001b[38;5;241m.\u001b[39mest) \u001b[38;5;241m+\u001b[39m (\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_collab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontent_score\u001b[49m)]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Combine the recommended items from collaborative and content-based filtering\u001b[39;00m\n\u001b[0;32m     16\u001b[0m hybrid_items \u001b[38;5;241m=\u001b[39m svdpp_items \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(content_recs)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "combine_recommendations(svdpp_model_predictions, content_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37a2db2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mhybrid_recs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAvatar\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[47], line 7\u001b[0m, in \u001b[0;36mhybrid_recs\u001b[1;34m(movie_input)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhybrid_recs\u001b[39m(movie_input):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#     collab = svdpp_model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#     content = metadata_recs(movie_input)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#     hybrid = collab + content\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#     hybrid = list(set(hybrid))\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m       hybrid \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_recommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvdpp_model_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent_recs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m hybrid[:top_n]\n",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m, in \u001b[0;36mcombine_recommendations\u001b[1;34m(svdpp_model_predictions, content_recs, weight_collab)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m svdpp_model_predictions:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m content_score \u001b[38;5;129;01min\u001b[39;00m content_recs:\n\u001b[1;32m---> 13\u001b[0m        hybrid_scores\u001b[38;5;241m.\u001b[39mappend((weight_collab \u001b[38;5;241m*\u001b[39m prediction\u001b[38;5;241m.\u001b[39mest) \u001b[38;5;241m+\u001b[39m (\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_collab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontent_score\u001b[49m))\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Combine the recommended items from collaborative and content-based filtering\u001b[39;00m\n\u001b[0;32m     16\u001b[0m hybrid_items \u001b[38;5;241m=\u001b[39m svdpp_items \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(content_recs)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "hybrid_recs('Avatar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca05ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
